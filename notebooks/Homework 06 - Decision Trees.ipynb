{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "> Note: sometimes your answer doesn't match one of \n",
    "> the options exactly. That's fine. \n",
    "> Select the option that's closest to your solution.\n",
    "\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this homework, we will use the California Housing Prices from [Kaggle](https://www.kaggle.com/datasets/camnugent/california-housing-prices).\n",
    "\n",
    "Here's a wget-able [link](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv):\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\n",
    "```\n",
    "\n",
    "The goal of this homework is to create a regression model for predicting housing prices (column `'median_house_value'`).\n",
    "\n",
    "\n",
    "### Preparing the dataset \n",
    "\n",
    "For this homework, we only want to use a subset of data. This is the same subset we used in homework #2.\n",
    "But in contrast to homework #2, we are going to use all columns of the dataset.\n",
    "\n",
    "First, keep only the records where `ocean_proximity` is either `'<1H OCEAN'` or `'INLAND'`\n",
    "\n",
    "Preparation:\n",
    "\n",
    "* Fill missing values with zeros.\n",
    "* Apply the log transform to `median_house_value`.\n",
    "* Do train/validation/test split with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1.\n",
    "* Use `DictVectorizer(sparse=True)` to turn the dataframes into matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_bedrooms = df.total_bedrooms.fillna(0)\n",
    "\n",
    "df[\"median_house_value\"] = np.log1p(df.median_house_value)\n",
    "\n",
    "df_fulltrain, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, random_state=1)\n",
    "\n",
    "dv = DictVectorizer(sparse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the `median_house_value` variable. \n",
    "\n",
    "* Train a model with `max_depth=1`.\n",
    "\n",
    "\n",
    "Which feature is used for splitting the data?\n",
    "\n",
    "* `ocean_proximity`\n",
    "* `total_rooms`\n",
    "* `latitude`\n",
    "* `population`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'median_house_value', 'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    'longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "    'total_bedrooms', 'population', 'households', 'median_income',\n",
    "    'ocean_proximity'\n",
    "]\n",
    "\n",
    "pred_column = 'median_house_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = df_train[features].to_dict(orient=\"records\")\n",
    "\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "Y_train = df_train[pred_column]\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1` (optional - to make training faster)\n",
    "\n",
    "\n",
    "What's the RMSE of this model on validation?\n",
    "\n",
    "* 0.045\n",
    "* 0.245\n",
    "* 0.545\n",
    "* 0.845\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10.\n",
    "* Set `random_state` to `1`.\n",
    "* Evaluate the model on the validation dataset.\n",
    "\n",
    "\n",
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "Consider 3 decimal places for retrieving the answer.\n",
    "\n",
    "- 10\n",
    "- 25\n",
    "- 50\n",
    "- 160\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values,\n",
    "  * try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "  * calculate the mean RMSE \n",
    "* Fix the random seed: `random_state=1`\n",
    "\n",
    "\n",
    "What's the best `max_depth`, using the mean RMSE?\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models. \n",
    "\n",
    "At each step of the decision tree learning algorithm, it finds the best split. \n",
    "When doing it, we can calculate \"gain\" - the reduction in impurity before and after the split. \n",
    "This gain is quite useful in understanding what are the important features for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the\n",
    "[`feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.feature_importances_)\n",
    "field. \n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parameters:\n",
    "  * `n_estimators=10`,\n",
    "  * `max_depth=20`,\n",
    "  * `random_state=1`,\n",
    "  * `n_jobs=-1` (optional)\n",
    "* Get the feature importance information from this model\n",
    "\n",
    "\n",
    "What's the most important feature (among these 4)? \n",
    "\n",
    "* `total_rooms`\n",
    "* `median_income`\n",
    "* `total_bedrooms`\n",
    "* `longitude`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Question 6\n",
    "\n",
    "Now let's train an XGBoost model! For this question, we'll tune the `eta` parameter:\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```\n",
    "\n",
    "Now change `eta` from `0.3` to `0.1`.\n",
    "\n",
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* Both give equal value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Submit the results\n",
    "\n",
    "- Submit your results here: https://forms.gle/Qa2SuzG7QGZNCaoV9\n",
    "- If your answer doesn't match options exactly, select the closest one.\n",
    "- You can submit your solution multiple times. In this case, only the last submission will be used\n",
    "\n",
    "## Deadline\n",
    "\n",
    "The deadline for submitting is October 23 (Monday), 23:00 CET. After that the form will be closed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
